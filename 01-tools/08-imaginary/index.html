<!DOCTYPE html>
<html>

<head>
  <link rel="stylesheet" type="text/css" href="https://jsxgraph.org/distrib/jsxgraph.css" />
  <link rel="stylesheet" type="text/css" href="/css/common.css" />
  <script>
    MathJax = {
      loader: { load: ['input/asciimath', 'output/chtml'] }
    }
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script type="text/javascript" src="https://jsxgraph.org/distrib/jsxgraphcore.js"></script>
  <script type="text/javascript" src="/utils.js"></script>
  <script type="text/javascript" src="/jsxgraph_styles.js"></script>
</head>

<body>
  <table class="page-table">
    <tr>
      <th>
        <h1>Imaginary Numbers</h1>
      </th>
    </tr>
    <tr>
      <td class="description">
        <h2>Background</h2>
        <p>
          The Renaissance was a period of intellectual awakening in which European thinkers rediscovered the classical
          literature of Greece and Rome.
          As a result of the Greeks being masters of geometry, European mathematicians inherited a conceptual framework
          in which a mathematical concept was not considered reliable unless you could offer a geometric proof.
        </p>
        <p>
          One powerful, but largely unspoken consequence of this approach was the assumption that if you could not draw
          your solution, then there was no solution.
          This is why Greek mathematicians widely rejected the idea that there could be a quantity called `zero`; it
          just seemed philosophically wrong: after all, how could non-being be, or more concretely, how could you draw a
          line with a length of `zero`?
        </p>
        <p>
          Reservations such as these became embedded into European thinking and it took several centuries for them to be
          unlearnt.
          However, as the Renaissance slowly transformed into the Enlightenment, mathematicians discovered that instead
          of writing out numerical relationships in words, a new <i>"algebraic"</i> notation offered a way to express
          relationships in a more compact form that was much easier manipulate.
        </p>
        <p>
          Then once mathematicians got used to using algebra, they found their proofs no longer needed to be anchored in
          geometry.
        </p>

        <h2>Squares and Square Roots</h2>
        <p>
          When you multiply a number by itself, you are said to have "squared" that number.
          Reversing this process is called "taking the square root".
          The point here is that when you square any of the normal counting numbers, the answer will always be positive:
        </p>
        <p>
          A positive number multipled by itself is positive: `2 xx 2 = 4`<br>
          And a negative number multipled by itself is also positive: `-3 xx -3 = 9`
        </p>
        <p>
          Similarly, when you take the square root of a number, you must remember that there are always two answers: one
          positive and the other negative.
        </p>
        <p>
          `sqrt 4 = pm 2`<br>`sqrt 9 = pm 3`
        </p>
        <p>
          For several centuries before Euler, mathematicians considered it impossible (or even morally wrong) to talk
          about the square root of a negative number.
          It was considered inconceivable for there to be a number that, when multiplied by itself, gave the answer
          `-1`.
        </p>
        <p>
          Yet these bizarre numbers simply would not go away &mdash; they kept haunting the solutions to cubic
          equations&hellip;
        </p>

        <h2>Making the Conceptual Leap</h2>
        <p>
          The fundamental problem here was a conceptual one &mdash; if I make the statement:
        </p>
        <p style="text-align: center; font-style: italic;">
          "I am holding the square root of nine apples"
        </p>
        <p>
          then I have stated (rather awkwardly) that I am holding `three` apples.
        </p>
        <p>
          `Three` is a real-world quantity &mdash; it represents a tangible quantity of things I can pick up &mdash; it
          is
          a number I can count to.
        </p>
        <p>
          But what answer can we give when attempting to calculate `sqrt (-9)`?
        </p>
        <p>
          It's not `+3` and its not `-3`, but a `3` must be involved somewhere &mdash; and herein lies the problem.
        </p>
        <p style="font-weight: bold; font-style: italic; text-align:center;">
          The answer is that we must accept the existence<br>of a kind of number we cannot count to
        </p>
        <p>
          If this makes your brain hurt, then don't worry &mdash; you're in good company.
        </p>
        <p>
          Mathematicians found the concept of <i>"a number you cannot count to"</i> deeply perplexing as there is no
          intuitive way to conceptualise such a quantity.
          After all, what tangible meaning could such a quantity have in the material world?
        </p>
        <p>
          In spite of this profound philosophical problem, the need to answer questions like <i>"What is the value of
            `sqrt (-9)`?"</i> simply would not go away.
        </p>
        <br>

        <h3>Living With Some Intellectual Discomfort</h3>
        <p>
          What mathematicians struggled to accept was the idea that this strange, intangible quantity could have any
          mathematical usefulness (However, as Euler later demonstrated, it turns out to be essential).
        </p>
        <p>
          <a href="https://en.wikipedia.org/wiki/Ren%C3%A9_Descartes" target="_new">Ren&eacute; Descartes</a> was one of
          many mathematicians who found these quantites deeply perplexing.
          Like so many of his contemporaries, he was unwilling to accept the intellectual discomfort created by a having
          to work with a quantity that appeared to have no direct applicability in the material world.
        </p>
        <p>
          It is easy to comprehend the statement <i>"I am holding `1` apple</i>, but what does it mean to say <i>"I am
            holding `sqrt (-1)` apples"</i>?
        </p>
        <p>
          Exactly how many apples is that?
          Can this statement even be considered valid?
        </p>
        <p>
          For a philosopher such as Descartes, the idea that mathematics should contain a type of quantity you cannot
          count to created a deep philosophical problem.
          So in his frustration (and no doubt, a certain degree of irritation), he gave these numbers the rather
          derogatory title of <a href="https://en.wikipedia.org/wiki/Imaginary_number#History"
            target="_new">"imaginary"</a>
          because to him, they could not be made to represent anything in the "real" world.
        </p>
        <p>
          It's unfortunate, but this name has stuck.
        </p>
        <br>

        <h3>So What Can We Calculate?</h3>
        <p>
          The first step is to rewrite `-9` as `9 xx -1`.
          Then at least we can calculate the square root of the positive part.
        </p>
        <p>
          `sqrt (9 xx -1)` simplifies to `3 xx sqrt (-1)`, but this is only a partial result because that pesky `sqrt
          (-1)` simply won't go away.
        </p>
        <br>

        <h3>The <i>i</i>'s Have It</h3>
        <p>
          Given that these numbers have been labelled "imaginary", and that it is awkward to continually have to write
          `sqrt (-1)` every time we want to refer to this quantity, mathematicians just use the letter `i` (physicists
          and electrical engineers however, tend to use the letter `j` instead).
        </p>
        <p>
          `i` is awkward to work with for the simple reason that our normal rules of arithmetic apply only to real
          numbers: and `i` is not real.
          So if we have to combine real numbers with imaginary numbers, then most of the time, we must simply accept the
          presence of `i`.
        </p>
        <table>
          <tr>
            <td style="vertical-align: top;">
              <p>
                However, when you multiply this imaginary number `i` by itself, depending on the number of operations
                you perform, the answer alternates between a real number (that is, one you can count to such as `+1` or
                `-1`) and another imaginary number (such as `i` or `-i`).
              </p>
              <p>
                If we want to display such numbers on a graph, then the convention is to plot real numbers on the X
                axis,
                and imaginary numbers on the Y axis.
                Such a graph looks like the one to the right:
              </p>
              <p>
                When we now multiply `i` by itself an increasing number of times, we get the following cycle of values:
              </p>
              <p>
                `i^0 = 1`<br>
                `i^1 = i`<br>
                `i^2 = i xx i = -1`<br>
                `i^3 = i xx i xx i = -i`<br>
                `i^4 = i xx i xx i xx i = 1` (and we're back to one again)<br>
                `i^5 = i xx i xx i xx i xx i = i`
              </p>
            </td>
            <td>
              <div id="imagRotBox" class="imagRotBox"></div>
            </td>
          </tr>
          <tr>
            <td colspan="2">This turns out to be an extremely useful property.</td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
  <script type="text/javascript" src="./main.js"></script>
</body>

</html>
